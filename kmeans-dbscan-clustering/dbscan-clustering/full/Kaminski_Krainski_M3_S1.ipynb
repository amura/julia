{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# First make sure to install all required packages.\n",
    "# You can do it by running the following command:"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# ]add Arrow CSV DataFrames Plots Clustering Distances FreqTables"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "LoadError",
     "evalue": "syntax: unexpected \"]\"",
     "traceback": [
      "syntax: unexpected \"]\"",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[8]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# If you launched Jupyter in directory with attached Project.toml and Manifest.toml\n",
    "# use below command to install required packages with fixed versions. \n",
    "# Check Project introduction for more information."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "#] instantiate"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m libfdk_aac_jll ── v2.0.2+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Fontconfig_jll ── v2.13.93+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m x265_jll ──────── v3.5.0+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m EarCut_jll ────── v2.2.3+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m PlotUtils ─────── v1.0.13\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m DataAPI ───────── v1.8.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m StatsBase ─────── v0.33.10\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Plots ─────────── v1.21.3\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m HTTP ──────────── v0.9.14\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Bzip2_jll ─────── v1.0.8+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Parsers ───────── v2.0.3\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m WeakRefStrings ── v1.3.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Missings ──────── v1.0.1\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m FilePathsBase ─── v0.9.10\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m GR_jll ────────── v0.59.0+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Cairo_jll ─────── v1.16.1+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m HarfBuzz_jll ──── v2.8.1+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m libass_jll ────── v0.15.1+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m x264_jll ──────── v2021.5.5+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m FreeType2_jll ─── v2.10.4+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MacroTools ────── v0.5.8\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m RecipesPipeline ─ v0.4.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m TimeZones ─────── v1.5.7\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m FFMPEG_jll ────── v4.4.0+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Graphite2_jll ─── v1.3.14+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m StructTypes ───── v1.7.3\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Compat ────────── v3.37.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Tables ────────── v1.5.1\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m RecipesBase ───── v1.1.2\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m StructArrays ──── v0.6.2\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m SentinelArrays ── v1.3.7\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m PooledArrays ──── v1.3.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Reexport ──────── v1.2.2\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m InvertedIndices ─ v1.1.0\n",
      "ERROR: Unexpected end of data : jl_fN8GWp7UtREU~\n",
      "┌ Warning: failed to extract archive downloaded from https://pkg.julialang.org/package/336ed68f-0bac-5ca0-87d4-7b16caf5d00b/c907e91e253751f5840135f4c9deb1308273338d\n",
      "└ @ Pkg.Operations /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:595\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m CSV ───────────── v0.9.1\n",
      "\u001b[32m\u001b[1m    Building\u001b[22m\u001b[39m TimeZones → `~/.julia/scratchspaces/44cfe95a-1eb2-52ea-b672-e2afdf69b78f/6c9040665b2da00d30143261aea22c7427aada1c/build.log`\n",
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mReexport\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mInvertedIndices\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mDataAPI\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mCompat\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mStructTypes\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mSentinelArrays\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mFilePathsBase\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mlibfdk_aac_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mx264_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mGraphite2_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mBzip2_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mPooledArrays\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mHTTP\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mx265_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mEarCut_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mMacroTools\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mMissings\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mTables\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mFreeType2_jll\u001b[39m\n",
      "\u001b[33m  ✓ \u001b[39m\u001b[90mParsers\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mLatexify\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mDataStructures\u001b[39m\n",
      "\u001b[33m  ✓ \u001b[39m\u001b[90mJSON\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mSortingAlgorithms\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mFontconfig_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mStructArrays\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mNamedArrays\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mWeakRefStrings\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mColors\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mCairo_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mCategoricalArrays\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mQt5Base_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mStatsBase\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mArrow\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mHarfBuzz_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mFreqTables\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mlibass_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mPrettyTables\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mClustering\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mFFMPEG_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mFFMPEG\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mGR_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mCSV\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mColorSchemes\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mGeometryBasics\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mGR\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mPlotUtils\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mRecipesPipeline\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mPlotThemes\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mDataFrames\n",
      "\u001b[32m  ✓ \u001b[39mPlots\n",
      "  51 dependencies successfully precompiled in 79 seconds (93 already precompiled)\n",
      "  \u001b[33m2\u001b[39m dependencies precompiled but different versions are currently loaded. Restart julia to access the new versions\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Import required libraries\n",
    "using Arrow\n",
    "#using CSV\n",
    "using DataFrames\n",
    "using Plots\n",
    "using Clustering\n",
    "using Distances\n",
    "using Random\n",
    "using Statistics\n",
    "using FreqTables"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "┌ Info: Precompiling Plots [91a5bcdd-55d7-5caf-9e0b-520d859cae80]\n",
      "└ @ Base loading.jl:1342\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mModule JSON with build ID 3143813306601 is missing from the cache.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mThis may mean JSON [682c06a0-de6a-54ab-a142-c8b1cf79cde6] does not support precompilation but is imported by a module that does.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Base loading.jl:1030\u001b[39m\n",
      "┌ Info: Skipping precompilation since __precompile__(false). Importing Plots [91a5bcdd-55d7-5caf-9e0b-520d859cae80].\n",
      "└ @ Base loading.jl:1047\n",
      "┌ Info: Precompiling FreqTables [da1fdf0e-e0ff-5433-a45f-9bb5ff651cb1]\n",
      "└ @ Base loading.jl:1342\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mModule JSON with build ID 3143813306601 is missing from the cache.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mThis may mean JSON [682c06a0-de6a-54ab-a142-c8b1cf79cde6] does not support precompilation but is imported by a module that does.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Base loading.jl:1030\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mModule JSON with build ID 3143813306601 is missing from the cache.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mThis may mean JSON [682c06a0-de6a-54ab-a142-c8b1cf79cde6] does not support precompilation but is imported by a module that does.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Base loading.jl:1030\u001b[39m\n",
      "┌ Info: Skipping precompilation since __precompile__(false). Importing FreqTables [da1fdf0e-e0ff-5433-a45f-9bb5ff651cb1].\n",
      "└ @ Base loading.jl:1047\n",
      "┌ Info: Precompiling CategoricalArrays [324d7699-5711-5eae-9e2f-1d82baa6b597]\n",
      "└ @ Base loading.jl:1342\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mModule JSON with build ID 3143813306601 is missing from the cache.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mThis may mean JSON [682c06a0-de6a-54ab-a142-c8b1cf79cde6] does not support precompilation but is imported by a module that does.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Base loading.jl:1030\u001b[39m\n",
      "┌ Info: Skipping precompilation since __precompile__(false). Importing CategoricalArrays [324d7699-5711-5eae-9e2f-1d82baa6b597].\n",
      "└ @ Base loading.jl:1047\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Read clean dataset from Arrow file into DataFrame\n",
    "sales_norm = DataFrame(Arrow.Table(\"./../../data-prep/sales_norm.arrow\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Convert DataFrame to Matrix and make sure that one product is one column in the resulting matrix\n",
    "cluster_data = Matrix(sales_norm)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Calculate Euclidean distances between all points\n",
    "dists = pairwise(SqEuclidean(), cluster_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Specify epsilons and minpts range\n",
    "eps_rng = 20.0:0.5:70.0\n",
    "minpts_rng = 1:6;"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Calculate average silhouettes values, number of clusters and mean clusters size \n",
    "#for each combination of hyperparameters\n",
    "avg_shts_m = Vector{Float64}[]\n",
    "no_clust_m = Vector{Int64}[]\n",
    "avg_clust_size_m = Array{Float64}[]\n",
    "for m in minpts_rng\n",
    "    avg_shts = Float64[]\n",
    "    no_clust = Int64[]\n",
    "    avg_clust_size = Float64[]\n",
    "    for e in eps_rng\n",
    "        clustering = dbscan(dists, e, m)\n",
    "        cluster_ids = clustering.assignments\n",
    "        if maximum(cluster_ids) <= 1\n",
    "            silh = NaN\n",
    "        else\n",
    "            idx = cluster_ids .!=0\n",
    "            silh = mean(silhouettes(cluster_ids[idx], dists[idx, idx]))\n",
    "        end\n",
    "        push!(avg_shts, silh)\n",
    "        push!(no_clust, maximum(cluster_ids))\n",
    "        push!(avg_clust_size, mean(clustering.counts))\n",
    "    end\n",
    "    push!(avg_shts_m, avg_shts)\n",
    "    push!(no_clust_m, no_clust)\n",
    "    push!(avg_clust_size_m, avg_clust_size)\n",
    "end"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot average silhouettes values\n",
    "# Notice that some of the lines are 'punctured' - these are cases when silhouettes value can't be computed. \n",
    "# For small values of epsilon and high 'm' all observations are classified as outliers\n",
    "# For big values of epsilon all observations may be classified as one cluster (with few additional outliers)\n",
    "# For epsilon > 65.0 even with m=1 all observations are assigned to one cluster\n",
    "plot(eps_rng, avg_shts_m, xlab = \"epsilon\", ylab = \"Mean silhouette value\", \n",
    "    labels = permutedims([\"m=\"*string(m) for m in 1:6]), linewidth = 2)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot number of clusters\n",
    "plot(eps_rng, no_clust_m[2:end], xlab = \"epsilon\", ylab = \"Number of clusters\", \n",
    "    labels = permutedims([\"m=\"*string(m) for m in 2:6]), linewidth = 2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot average clusters size\n",
    "plot(eps_rng, avg_clust_size_m[2:end], xlab = \"epsilon\", ylab = \"Average cluster size\",\n",
    "        labels = permutedims([\"m=\"*string(m) for m in 2:6]), linewidth = 2, legend=:topleft)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "DBSCAN is producing really small clusters up to 40.0 value of epsilon - we want to have few clusters we can analyze and write down the findings. Getting back to the average silhouette plot, we can se that for epsilon > 40.0 there is a spike around epsilon equal to 50.0 for m=5 or m=6. \n",
    "\n",
    "We'll use epsilon=50.0 and m=6 as hyperparameter values for further analysis."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Produce final DBSCAN clustering\n",
    "opt_clustering = dbscan(dists, 50.0, 6)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Check the members count in each cluster\n",
    "# There are 458 products considered as outliers\n",
    "#observations are dispersed in high dimensional space and don't create dense areas\n",
    "freqtable(opt_clustering.assignments)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot clusters average sales  (also include outliers as separate cluster)\n",
    "# Each cluster has some distinct characteristic we should summarize for the recipients of the report\n",
    "plot(hcat([mean(cluster_data[:, opt_clustering.assignments .== i], dims=2) for i in 0:2]...), \n",
    "    xlab=\"Week\", ylab=\"Normalized sales\", labels=[0 1 2], linewidth=2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot cluster sales standard deviations\n",
    "# Variability visibly differs between groups\n",
    "plot(hcat([std(cluster_data[:, opt_clustering.assignments .== i], dims=2) for i in 0:2]...), \n",
    "    xlab=\"Week\", ylab=\"Normalized sales\", labels=[0 1 2], linewidth=2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load k-means assignments from Milestone 2\n",
    "kmeans_assignments = parse.(Int64, readlines(\"kmeans_assignments.txt\"));"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Produce two-way table for DBSCAN and k-means assignments\n",
    "# As we can see, Cluster 2 from DBSCAN consists almost only of observations from k-means Cluster 4\n",
    "# Outliers and Cluster 1 from DBSCAN have no clear mapping to k-means while considering observations membership\n",
    "freqtable(opt_clustering.assignments, kmeans_assignments)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Save DBSCAN assignments to the text file\n",
    "open(\"dbscan_assignments.txt\", \"w\") do io\n",
    "  foreach(e -> println(io, e), opt_clustering.assignments)\n",
    "end"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Analysis of clustering results**\n",
    "\n",
    "Based on DBSCAN clustering evaluation we produced 2 clusters with 353 observations in total (we removed 458 products as outliers).\n",
    "\n",
    "* Cluster 1 has slowly increasing sales until mid-year when after rapid rise we notice even bigger drop in sales. Afterwards sales value is recovering to skyrocket in last few weeks\n",
    "* Cluster 2 osciliate around steady sales state until mid-year when it drops to really small sales amount. Products are recovering quite fast, but there is sudden drop in last few weeks of observed period.\n",
    "* Outliers are quite stable in terms of average sales, but are still affected by mid-year drop\n",
    "\n",
    "Variance analysis shows that variability for oultiers is stable throughout analyzed period. Cluster 2 also exposes quite stable variability and lower in value compared to outliers. Cluster 1 has suddenly changing variance during mid- and end-year spike.\n",
    "\n",
    "We produced two distinct clusterings using `k-means` and `DBSCAN` methods. Both algorithms are struggling to extract clearly separated groups of products, but with proper evaluation and validation we gained valuable business insights. Considering results from both clustering methods we can also see similar patterns for particular clusters:\n",
    "* DBSCAN Cluster 1 is mostly a subset of k-means Clusters 1 and 2\n",
    "* DBSCAN Cluster 2 is almost a subset of k-means Cluster 4\n",
    "\n",
    "Both clustering results may be relevant for product team and person with in-depth knowledge about the products may provide additional comments regarding clustering quality. \n",
    "\n",
    "As a final technical detail, we want to highlight that our goal was to spot distinct groups in the product base regardless of the density of these groups. DBSCAN catches dense regions well, but related products are not guaranteed to be close to one another. We consider k-means to be our main analysis technique and DBSCAN as a validation tool."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.2",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}